\documentclass{article}
\listfiles
\usepackage{amsmath, amsthm, commath}
\usepackage[english]{babel}
\usepackage[style=numeric, maxnames=999, backend=biber]{biblatex}
\usepackage{ccool}
\edef\ccoolvers{\csname ver@ccool.sty\endcsname}
\usepackage{csquotes}
\usepackage{datetime2}
\DTMsetup{datesep=/,style=mmddyyyy}
\usepackage[T1]{fontenc}
\begin{filecontents}{\jobname.bib}
@phdthesis{oh-2005,
        author = {Olympia Hadjiliadis},
        title = {Change--point detection of two--sided alternatives in the Brownian motion model and its connection to the gambler's ruin problem with relative wealth perception},
        year = {2005},
        school = {Columbia University}
}
@misc{ccool,
        author = {Erwann Rogard and Olympia Hadjiliadis},
        title = {The \texttt{ccool} package},
        year = {2020},
        url = {https://github.com/rogard/ccool}
}
\end{filecontents}
\addbibresource{\jobname.bib}
\usepackage{tcolorbox}
\tcbuselibrary{listings, breakable}
\newtcblisting[auto counter]
{listing}[2][]{
  noparskip,
  breakable,
  colback=white,
  colframe=black,
  opacitybacktitle=.8,%
  fonttitle=\bfseries,
  title=Listing~\thetcbcounter. #1,
  arc=0pt,
  outer arc=0pt,
  boxrule=1pt,
  listing and text,
  % text only,
  #2
}
\usepackage{hyperref}

\providecommand\doclist[1]{Listing~\autoref{listing:#1}}

\listfiles

% \left\{\1\right\}

\title{Typesetting a math thesis with \texttt{ccool}}

\author{Erwann Rogard and Olympia Hadjiliadis\thanks{\url{http://math.hunter.cuny.edu/~olympia/}}}
\date{\today}


\begin{document}

\maketitle

\begin{abstract}
  To test and showcase \texttt{ccool}\cite{ccool},
  here's a portion of an applied math thesis\cite[pp. 25-27]{oh-2005} typeset using it.
\end{abstract}

\vspace*{\fill}

\tableofcontents

\vspace*{\fill}

This document was generated using \ccoolvers. 

\vspace*{\fill}

\clearpage

%\part{Listing}\label{part:listing}

\phantomsection
\addcontentsline{toc}{section}{\doclist{pre}: preamble}

\begin{listing}[Preamble\footnote{Check the source file for exhaustivity}]
  {label=listing:pre, listing only}
  \usepackage{amsmath, amsthm, commath}
  \usepackage{csquotes}
  \usepackage[T1]{fontenc}
  \newtheorem{lemma}{Lemma}
  \AfterEndEnvironment{lemma}{\CcoolHook}
  \newtheorem{definition}{Definition}
  \AfterEndEnvironment{definition}{\CcoolHook}
\end{listing}
\newtheorem{lemma}{Lemma}
\AfterEndEnvironment{lemma}{\CcoolHook}
\newtheorem{definition}{Definition}
\AfterEndEnvironment{definition}{\CcoolHook}

\phantomsection
\addcontentsline{toc}{section}{\doclist{short}. Short}

\begin{listing}[Short]
  {label=listing:short}
  \NewDocumentCommand\EvalAt{m}{(#1)}

  \Ccool{ SuchThat = { ;~ }, Time = { t }, Process = { \xi }, StopT = T }
  [The CUSUM statistic process and the corresponding one-sided CUSUM stopping time are defined as follows:
  \begin{definition}\label{the CUSUM statistic} Let~]
    { Scale = { \lambda }, Real = {\mathcal{R}} }+*s{{~\in~}}[~and~]
    { CUSUMthresh = { \nu } }+*o{$#1\in\Real^{+}$.}
    [~Define the following processes:]
    { LogWald = { u },  CUSUMst = { \StopT_{c} }, CUSUM = { y }, LogWaldInf = { m } }+
    [\begin{enumerate}
    \item{$\LogWald_{\Time}\EvalAt{ \Scale } = \Scale \Process_{\Time} - \frac{1}{2} \Scale^2\Time$;
        $\LogWaldInf_{\Time}\EvalAt{ \Scale } = \inf_{ 0\le s \le \Time } \CUSUM_{s}\EvalAt{ \Scale }$.}
    \item{$\CUSUM_{\Time}\EvalAt{ \Scale } =  \LogWaldInf_{\Time}\EvalAt{ \Scale } - \LogWald_{\Time}\EvalAt{ \Scale }\ge0$, which is the CUSUM statistic process.}
    \item{$\CUSUMst\EvalAt{ \Scale, \LogWaldInf } = \inf \left[ \Time \ge 0 \SuchThat \CUSUM_{\Time}\EvalAt{\Scale} \ge \LogWaldInf \right]$, which is the CUSUM stopping time.} \end{enumerate}\end{definition}\par]{}
\end{listing}

\phantomsection
\addcontentsline{toc}{section}{\doclist{long}. Long.}

\begin{listing}[Long]
  {label=listing:long}
  \NewDocumentCommand\Integrate{ E{_^}{{0}{\infty}} m E{v}{{\Time}} }
  {\int_{#1}^{#2} #3 \dif#4}
  \NewDocumentCommand\EvalAt{m}{(#1)}
  \NewDocumentCommand\Event{m}{\left\{#1\right\}}
  \NewDocumentCommand\OpRHS{m}{\left[#1\right]}
  \NewDocumentCommand\Sequence{mo}
  {\left\{#1\right\}\IfValueT{#2}{_{#2}}}
  
  \Ccool{
    Cond = { \mid },
    Cont = { C },
    EssSup = { \textrm{ess\,sup} },
    Expect = { E }, 
    Measure = { P },
    SigmaAlg = { \mathcal{F} },
    SigmaAlgOp = { \operatorname{\sigma} },
    SuchThat = { ;~ },
    Time = { t },
    Union = { \cup }                                                      
  }
  [We begin by considering the observation process~]
  { Process = { \xi } }*o{$\Sequence{#1}[\Time>0]$} 
  [ with the following dynamics:]
  { Drift = { \mu_i }, Noise = { w }, ChangePoint = { \tau } }   
  [\begin{displaymath}
    \Process_{\Time} = \left\{
      \begin{array}{ll}
        \dif\Noise_{\Time}  & \Time \le \ChangePoint \\
        \Drift\, \dif\Time + \dif\Noise_{\Time} &  t > \ChangePoint,~~i=1,2.
      \end{array}\right\}
  \end{displaymath}where $\ChangePoint$, the time of change, is assumed to be an unknown constant; $\Drift$, the possible drifts the process can change to, are assumed known, but the specific drift the process is changing to is assumed to be determined by nature and is thus unknown. Our goal is to detect the change and not to infer which of the change occurred.]{}
  \Ccool[The probability triple is~]
  { Space = { \Cont{[}0,\infty{)} }, IdxMeasure = { \Measure^i_{\ChangePoint} } } 
  [\begin{equation*}
    \left(\Space, \SigmaAlg_{\infty}, \Sequence{\SigmaAlg_{\Time}}, \Measure\right)~\forall~i=1,2,~\rm{and}~\ChangePoint~\in~{[}0,\infty{)},
  \end{equation*}where $\Space$ is the space of continuous functions,
  $\SigmaAlg_{\Time} = \SigmaAlgOp\left\{\Process_{\Time}, \Time \ge 0\right\}$, $\SigmaAlg_{\infty} = \left\{\SigmaAlg_{\Time}\right\}_{\Time=\infty} = \Union_{\Time>0} \SigmaAlg_{\Time}$, and $\IdxMeasure$ is the family of probability measures generated by the observation process $\Sequence{\Process_{\Time}}$ when the change is $i=1,2$ and the change-point is $\ChangePoint$. Notice that $\Measure_{\Time=\infty}$ is the Wiener measure.\par]{}

  \Ccool[The objective is to detect the change as soonas possible, which is achieved through the means of a stopping rule ]
  { StopT = T }* 
  [ adapted to the filtration $\SigmaAlg_{\Time}$. This means that at each instant $\Time$ the information that is available up to that instant. If~]
  { MeasureStop = { \Measure_{\ChangePoint} } }* 
  [~is the true distribution, then in the event that $\Event{\StopT \ge \ChangePoint}$ it is desired that the conditional expectation of $\StopT-\ChangePoint$ should be small. Notice that $\Event{\StopT \ge \ChangePoint} \in~$]
  { SigmaAlgStop = { \SigmaAlg_{\ChangePoint} } }*[.\par]{} 
  
  \Ccool[But  of course, $\forall~\Time > \ChangePoint$, $\left\{\StopT = \Time\right\} \in  \SigmaAlg_{t} \supset  \SigmaAlgStop$. One of the possible performance measures of the  detection delay, suggested by Lorden in \textdel{\cite{Lorden:1971}},
  considers the worst detection delay over all paths before the change and all possible change points $\ChangePoint$. It is]
  { Penalty = J } 
  [\begin{equation}
    {\Penalty}\EvalAt{\ChangePoint}=\sup_{\ChangePoint}\,
    \EssSup\, \Expect_{\ChangePoint}\OpRHS{ (\StopT-\ChangePoint)^{+}\Cond\SigmaAlgStop },
    \label{oLorden}
  \end{equation}  giving rise to the following constrained stochastic optimization problem:]{}

  \Ccool{ OptimThresh = { \gamma } } 
  [\begin{equation}
    \begin{array}{c}
      \displaystyle \inf_{\StopT} {\Penalty}\EvalAt{\StopT}\\
      \Expect_{\infty}\OpRHS{\StopT} \geq \OptimThresh.
    \end{array}\label{eqnproblemL}
  \end{equation}\par]{}

  \Ccool[One can immediately notice that the small detection delay requirement is offset by the requirement that the frequency of "false reactions" be controlled. In other words, the meaning of the requirement that $\Expect_{\infty}\OpRHS{\StopT}\geq \OptimThresh$ is that,  the mean time between alarms under the Wiener measure (i.e. the  measure corresponding to there not being any change) is at least  as big as $\OptimThresh$. One can also write $$\Expect_{\infty}\OpRHS{\StopT} = \Integrate{ \Measure_{\infty}\OpRHS{\StopT > \Time} }$$  and notice that the above requirement is equivalent to the  requirement of a small $\Measure_{\infty}\OpRHS{\StopT{<}\Time}$, which is the probability of a false alarm (type I error).\par]{}

  \Ccool[It is easily seen that, in seeking solutions to the above problem,  we can restrict our attention to stopping times that satisfy the false alarm constraint with equality. This is because, if $\Expect_{\infty}\OpRHS{\StopT} > \OptimThresh$, we can produce a stopping time that achieves the constraint with equality without increasing the  detection delay, simply by randomizing between $\StopT$ and the stopping time that is identically $0$. This was first seen by Moustakides in the discrete case \char`[see \textdel{\cite{Moustakides:1986}}.\char`]\par]{}

  \Ccool[To this effect, we introduce the following definition:
  \begin{definition}Define~]
    { StopTthresh = { \mathcal{K} } }+* 
    [ to be the set of all stopping rules $\StopT$ that
    are adapted to $\SigmaAlg_{\Time}$ and that satisfy $\Expect_{\infty}\OpRHS{T}=\OptimThresh$.
  \end{definition}\par]{}
  
  \Ccool[The CUSUM statistic process and the corresponding one-sided CUSUM stopping time are defined as follows:
  \begin{definition}\label{the CUSUM statistic}Let~]
    { Scale = { \lambda }, Real = {\mathcal{R}} }+*s{{~\in~}}
    [~Define the following processes:]
    { CUSUMthresh = { \nu } }+*o{$#1\in\Real^{+}$.}[]
    { LogWald = { u },  CUSUMst = { \StopT_{c} }, CUSUM = { y }, LogWaldInf = { m } }+
    [\begin{enumerate}
    \item{$\LogWald _{\Time}\EvalAt{ \Scale } = \Scale \Process_{\Time} - \frac{1}{2} \Scale^2\Time$;
        $\LogWaldInf _{\Time}\EvalAt{ \Scale } = \inf_{ 0\le s \le \Time }  \CUSUM_{s}\EvalAt{ \Scale }$.}
    \item{$\CUSUM _{\Time}\EvalAt{ \Scale } =  \LogWaldInf _{\Time}\EvalAt{ \Scale }-   \LogWald _{\Time}\EvalAt{ \Scale }\ge0$, which is the CUSUM statistic process.}
    \item{$\CUSUMst\EvalAt{ \Scale, \LogWaldInf } = \inf \OpRHS{ \Time \ge 0 \SuchThat \CUSUM_{\Time}\EvalAt{\Scale} \ge \LogWaldInf }$, which is the CUSUM stopping time.} \end{enumerate}\end{definition}\par]{}
  
  \Ccool[We are now in a position to examine two very important properties  of the one-sided CUSUM stopping time. The first is a characteristic specifically inherent in the CUSUM statistic, and is summarized in the following lemma: \begin{lemma}\label{l2} Fix $\ChangePoint \in {[}0,\infty{)}$. Let $\Time\ge\ChangePoint$, and consider the process $$\CUSUM_{\Time, \ChangePoint} =  \LogWald_{\Time}-\LogWald_{\ChangePoint}-\inf_{\ChangePoint\le s\le \Time}(\LogWald_{\Time}-\LogWald_{\ChangePoint}).$$
    This is the CUSUM process when starting at time $\ChangePoint$. We have that $\CUSUM_{\Time}\ge \CUSUM_{\Time,\ChangePoint}$ with equality if $\CUSUM_{\ChangePoint}=0$. \end{lemma}\par
  \begin{proof} Note that\begin{equation}\CUSUM_{\Time}=\CUSUM_{\Time,\ChangePoint}
      +\left(\inf_{\ChangePoint\le s\le \Time}(\LogWald_{s}-\LogWald_{\ChangePoint})
        +\CUSUM_{\ChangePoint}\right)^{+}\ge \CUSUM_{t,\ChangePoint} \label{restart}
    \end{equation} and that $\inf_{\ChangePoint\le s\le \Time}(\LogWald_{s}-\LogWald_{\ChangePoint})\le0$.
  \end{proof}]{}
\end{listing}
% 
%\part{Other}

\phantomsection
\addcontentsline{toc}{section}{References}
% \printbibliography[heading=subbibliography]
\printbibliography[heading=bibliography]

\end{document}
